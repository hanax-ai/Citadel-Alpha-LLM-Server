# If standard installation fails, try with specific options
pip install flash-attn --no-build-isolation --no-cache-dir

# Or install pre-compiled wheel if available
pip install flash-attn --find-links https://github.com/Dao-AILab/flash-attention/releases